<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="UTF-8">
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Noto+Sans+JP:300,400,700&display=swap&subset=japanese" rel="stylesheet">
    <!-- CSS -->
    <link rel="stylesheet" href="{{ url_for('static', filename='index.css') }}" />
  </head>
  <body>
    <div id="moodChecker">
      <div id="chat"></div>
      <input type="text" id="chat-input"> <button onclick="sendMessage()">Send</button>
    </div>

    <div id="highFive">
      <button onclick="toggleVideo()" id="toggleButton" type="button">
        Toggle Video
      </button>
      <video id="video"></video>
      <canvas id="canvas" class="border"></canvas>
    </div>
  </body>
  <!-- Load the handtrackjs model. -->
  <script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"> </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.3.0/socket.io.js"></script>
  <script>
    /**************
    Send Socket IO
    **************/

    var socket = io()

    function sendMessage() {
        console.log(document.getElementById("chat-input").value)
        socket.emit('message',document.getElementById("chat-input").value)
    }
    socket.on("new_message", (data) => {
      document.getElementById("chat").innerHTML += "<br>" + data
    })

    /**************
    HandTrack.js
    **************/
    var isVideo = false;
    var model = null;
    const modelParams = {
        flipHorizontal: false,   // flip e.g for video
        maxNumBoxes: 10,        // maximum number of boxes to detect
        iouThreshold: 0.5,      // ioU threshold for non-max suppression
        scoreThreshold: 0.6,    // confidence threshold for predictions.
    }
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const context = canvas.getContext('2d');
    var toggleButton = document.getElementById("toggleButton");

    function toggleVideo() {
        if (!isVideo) {
            startVideo();
        } else {
            handTrack.stopVideo(video)
            isVideo = false;
        }
    }

    function startVideo() {
        handTrack.startVideo(video).then(function (status) {
            console.log("video started", status);
            if (status) {
                isVideo = true
                runDetection()
            }
        });
    }

    function runDetection() {
        model.detect(video).then(predictions => {
            console.log("Predictions: ", predictions);
            model.renderPredictions(predictions, canvas, context, video);
            if (isVideo) {
                requestAnimationFrame(runDetection);
            }
        });
    }

    // Load the model.
    handTrack.load(modelParams).then(lmodel => {
        // detect objects in the image.
        model = lmodel
        toggleButton.disabled = false
    });


  </script>
</html>
